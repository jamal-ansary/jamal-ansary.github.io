<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jamal Ansary </title>
  
  <meta name="author" content="Jamal Ansary">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jamal Ansary</name>
              </p>
              <p>
                  I am a master student at <a href="https://www.utoledo.edu/"> University of Toledo </a>, where I work on computer vision and machine learning under supervision of Dr. Brian Trease.
              </p>
              <p>
                At Google I've worked on <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
                I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:jansary@rockets.utoledo.edu">Email</a> &nbsp/&nbsp
                <a href="data/jamal-CV.pdf">CV</a> &nbsp/&nbsp
                
                <a href="https://scholar.google.com/citations?user=qxyNU2UAAAAJ&hl=en&authuser=2">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/jamal-ansary/">Linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/jamal-ansary">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/IMG_1037(1).jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/IMG_1037(1).jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing.
                Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images.
                Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
                <div class="two" id='nerfbake_image'>
                    <video width=100% height=100% muted autoplay loop>
                        <source src="images/nerfbake_15.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <img src='images/nerfbake_160.png' width="160">
            </div>
            <script type="text/javascript">
                function nerfbake_start() {
                    document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                    document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
            </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://www.sciencedirect.com/science/article/pii/S2666389920300945">
                <papertitle>Machine-Learning Approaches in COVID-19 Survival Analysis and Discharge-Time Likelihood Prediction Using Clinical Data</papertitle>
            </a>
            <br>

            <strong>MohammadrezaNemati</strong>,
            <strong>JamalAnsary</strong>,
            <strong>NazafarinNemati</strong>



            <p>-hospital mortality andrecovery:  application of machine learning on COVID-19clinical data.</p>
        </td>

    <tr onmouseout="flyspin_stop()" onmouseover="flyspin_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
            <div id='flyspin' class='hidden'><img src="images/3dgifmaker76347.gif"></div>
            <div id='flystill'>
                <a href="images/3dgifmaker76347.gif.gif"><img src="images/2-Figure1-1.png"></a>
            </div>
            <script type="text/javascript">
                function flyspin_start() {
                    document.getElementById('flyspin').style.display = 'inline';
                    document.getElementById('flystill').style.display = 'none';
                }

                function flyspin_stop() {
                    document.getElementById('flyspin').style.display = 'none';
                    document.getElementById('flystill').style.display = 'inline';
                }
                flyspin_stop()
            </script>
        </td>
        <td width="75%" valign="middle">
            <a href="https://drive.google.com/file/d/1shvItvx_8Sb8QNXhrOXkuRmx2618iwNJ/view?usp=sharing">
                <papertitle>Volumetric Semantic Segmentation using Pyramid Context Features</papertitle>
            </a>
            <br>
            <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://big.lbl.gov/">Soile V. E. Ker&aumlnen</a>, <a href="http://www.lbl.gov/gsd/biggin.html">Mark D. Biggin</a>,
            <br> <a href="http://dwknowles.lbl.gov/">David W. Knowles</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
            <br>
            <em>ICCV</em>, 2013
            <br>
            <a href="https://drive.google.com/file/d/1htiLpMAcYLtuBthmAb4XHnOYxUbkfnqR/view?usp=sharing">supplement</a> /
            <a href="https://drive.google.com/file/d/1qoYeFNa443myn2SfcdhmCsYBqE9xQrPD/view?usp=sharing">poster</a> /
            <a href="data/BarronICCV2013.bib">bibtex</a> / <a href="http://www.youtube.com/watch?v=Y56-FcfnlVA&hd=1">video 1</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="http://www.youtube.com/watch?v=mvRoYuP6-l4&hd=1">video 2</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmSF9YdWJjQmh4QW8/view?usp=sharing">code &amp; data</a>
            <p>
                We present a technique for efficient per-voxel linear classification, which enables accurate and fast semantic segmentation of volumetric Drosophila imagery.
            </p>
        </td>
    </tr>

    <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/3DSP_160.jpg" alt="3DSP" width="160" height="120" style="border-style: none">
        </td>
        <td width="75%" valign="middle">
            <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmbG1tOGIta3N1Wjg/view?usp=sharing" id="3DSP">
                <papertitle>3D Self-Portraits</papertitle>
            </a>
            <br>
            <a href="http://www.hao-li.com/">Hao Li</a>, <a href="http://www.evouga.com/">Etienne Vouga</a>, Anton Gudym, <a href="http://www.cs.princeton.edu/~linjiel/">Linjie Luo</a>, <strong>Jonathan T. Barron</strong>, Gleb Gusev
            <br>
            <em>SIGGRAPH Asia</em>, 2013
            <br>
            <a href="http://www.youtube.com/watch?v=DmUkbZ0QMCA">video</a> / <a href="http://shapify.me/">shapify.me</a> / <a href="data/3DSP_siggraphAsia2013.bib">bibtex</a>
            <p>Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D sensor.</p>
        </td>




    <tr onmouseout="flyspin_stop()" onmouseover="flyspin_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
            <div id='flyspin' class='hidden'><img src="images/3dgifmaker47860.gif"></div>
            <div id='flystill'>
                <a href="images/3dgifmaker47860.gif"><img src="images/1-s2.0-S2666389920300945-fx1.jpg"></a>
            </div>
            <script type="text/javascript">
                function flyspin_start() {
                    document.getElementById('flyspin').style.display = 'inline';
                    document.getElementById('flystill').style.display = 'none';
                }

                function flyspin_stop() {
                    document.getElementById('flyspin').style.display = 'none';
                    document.getElementById('flystill').style.display = 'inline';
                }
                flyspin_stop()
            </script>
        </td>
        <td width="75%" valign="middle">
            <a href="https://drive.google.com/file/d/1shvItvx_8Sb8QNXhrOXkuRmx2618iwNJ/view?usp=sharing">
                <papertitle>Volumetric Semantic Segmentation using Pyramid Context Features</papertitle>
            </a>
            <br>
            <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://big.lbl.gov/">Soile V. E. Ker&aumlnen</a>, <a href="http://www.lbl.gov/gsd/biggin.html">Mark D. Biggin</a>,
            <br> <a href="http://dwknowles.lbl.gov/">David W. Knowles</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
            <br>
            <em>ICCV</em>, 2013
            <br>
            <a href="https://drive.google.com/file/d/1htiLpMAcYLtuBthmAb4XHnOYxUbkfnqR/view?usp=sharing">supplement</a> /
            <a href="https://drive.google.com/file/d/1qoYeFNa443myn2SfcdhmCsYBqE9xQrPD/view?usp=sharing">poster</a> /
            <a href="data/BarronICCV2013.bib">bibtex</a> / <a href="http://www.youtube.com/watch?v=Y56-FcfnlVA&hd=1">video 1</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="http://www.youtube.com/watch?v=mvRoYuP6-l4&hd=1">video 2</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmSF9YdWJjQmh4QW8/view?usp=sharing">code &amp; data</a>
            <p>
                We present a technique for efficient per-voxel linear classification, which enables accurate and fast semantic segmentation of volumetric Drosophila imagery.
            </p>
        </td>
    </tr>

    <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/3DSP_160.jpg" alt="3DSP" width="160" height="120" style="border-style: none">
        </td>
        <td width="75%" valign="middle">
            <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmbG1tOGIta3N1Wjg/view?usp=sharing" id="3DSP">
                <papertitle>3D Self-Portraits</papertitle>
            </a>
            <br>
            <a href="http://www.hao-li.com/">Hao Li</a>, <a href="http://www.evouga.com/">Etienne Vouga</a>, Anton Gudym, <a href="http://www.cs.princeton.edu/~linjiel/">Linjie Luo</a>, <strong>Jonathan T. Barron</strong>, Gleb Gusev
            <br>
            <em>SIGGRAPH Asia</em>, 2013
            <br>
            <a href="http://www.youtube.com/watch?v=DmUkbZ0QMCA">video</a> / <a href="http://shapify.me/">shapify.me</a> / <a href="data/3DSP_siggraphAsia2013.bib">bibtex</a>
            <p>Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D sensor.</p>
        </td>
    </tr>



</tr>
        </tbody></table>
    
  
</body>

</html>
